# Steam Data Analysis

Ovaj projekat koristi **Kafka producer i consumer** kako bi se u realnom vremenu obradio dataset iz stream-a koji se nalazi u Docker kontejneru. Projekat je razvijen za **Grupu 3**, a podaci se preuzimaju sa `http://localhost:5001/stream/type3`.

Cilj projekta je da se podaci iz stream-a transformiÅ¡u i saÄuvaju u CSV fajlu, pri Äemu se obrada prekida kada se poÅ¡alje poruka `"close"` sa strane producer-a.

---

## â–¶ï¸ Pokretanje stream-a

1. **Preuzmi Docker `.tar` fajl za grupu 3**  
   *(link ubaciti ovde kada bude dostupan)*

2. **UÄitaj Docker sliku:**
```bash
docker load -i C:\Users\user\Downloads\bigdata-g3.tar
```

3. **Pokreni Docker kontejner:**
```bash
docker run -d -p 5001:5000 --name bigdata-g3 bigdata-g3:latest
```

4. **Proveri da li kontejner radi:**
Otvori u browseru:
```
http://localhost:5001/health-check
```
Ako je sve u redu, videÄ‡eÅ¡ odgovor: `Success`

5. **Stream podataka:**
```
http://localhost:5001/stream/type3
```

---

## âš™ï¸ Pokretanje Java aplikacije

Nakon Å¡to je stream aktivan, pokreni sledeÄ‡e klase:

- `Producer.java` â€“ preuzima podatke iz stream-a i Å¡alje ih kao Kafka poruke
- `ConsumerF.java` â€“ Kafka consumer koji snima podatke u CSV fajl
- `ConsumerT.java` â€“ Kafka consumer koji samo prikazuje podatke u konzoli

**Napomena:** Kada producer poÅ¡alje `"close"` poruku, consumer automatski prekida sa radom.

---

## ğŸ“‚ ObjaÅ¡njenje koda

### `Producer.java`
- UÄitava JSON podatke sa URL-a `http://localhost:5001/stream/type3`
- Parsira svaki JSON objekat liniju po liniju
- Å alje svaki objekat kao Kafka poruku na temu `"steam-data"`
- Kada se zavrÅ¡i stream, Å¡alje `"close"` poruku

### `ConsumerF.java`
- Prima Kafka poruke sa teme `"steam-data"`
- ÄŒuva sve poruke u CSV fajl (`output.csv`)
- Kada primi `"close"`, zavrÅ¡ava pisanje i zatvara fajl

### `ConsumerT.java`
- Prima Kafka poruke sa teme `"steam-data"`
- Ispisuje podatke u konzolu bez snimanja
- TakoÄ‘e prekida na `"close"` poruku

---
